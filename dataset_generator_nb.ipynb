{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT='INPUT/'\n",
    "PATH_OUTPUT='OUTPUT/'\n",
    "SIZE_PATCH=120\n",
    "\n",
    "INPUT_SIZE=9\n",
    "OUTPUT_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_images(paths_input,paths_output):\n",
    "    '''\n",
    "    Reads and saves as as an array image input and output\n",
    "    :paths_input array of paths of the input images that have to be read  \n",
    "    :paths_output array of paths of the output images that have to be read  \n",
    "    returns input and output images as array\n",
    "    '''\n",
    "    input_ = []\n",
    "    output_ = []\n",
    "\n",
    "    for path_i in paths_input:\n",
    "        with h5py.File(path_i, 'r') as hf:\n",
    "            X =np.array(hf.get('data'))\n",
    "            input_.append(X)\n",
    "\n",
    "\n",
    "    for path_o in paths_output:\n",
    "        with h5py.File(path_o, 'r') as hf:\n",
    "            Y_build=np.array(hf.get('data'))\n",
    "            Y_build=(Y_build>0).astype(int)\n",
    "            Y_other= (1-Y_build).astype(int)\n",
    "            Y=np.stack((Y_build,Y_other),axis=2)\n",
    "            output_.append(Y)\n",
    "\n",
    "            \n",
    "    return np.asarray(input_),np.asarray(output_)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator():\n",
    "    '''\n",
    "    DatasetGenerator class\n",
    "    '''\n",
    "\n",
    "    # This decides whether \"unique\" keys should be included in the generator for each datapoint (typically useful for feature caching)\n",
    "    include_keys = False\n",
    "\n",
    "    #img_size = DATA_PATCH_INPUT_SIZE\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, paths_input: np.ndarray,paths_output: np.ndarray, batch_size: int = None):\n",
    "        self.paths_input = paths_input\n",
    "        self.paths_output = paths_output\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    @classmethod\n",
    "    def from_root_folder(cls, root_folder: str, *, batch_size: int = None,max_data_size:  int = None):\n",
    "        paths_input = []\n",
    "        paths_output=[]\n",
    "        \n",
    "        \n",
    "        for filename in sorted(os.listdir(root_folder+PATH_INPUT))[:max_data_size]:\n",
    "            paths_input.append(os.path.join(root_folder+PATH_INPUT, filename))\n",
    "\n",
    "        for filename in sorted(os.listdir(root_folder+PATH_OUTPUT))[:max_data_size]:\n",
    "\n",
    "            paths_output.append(os.path.join(root_folder+PATH_OUTPUT, filename))\n",
    "        \n",
    "        \n",
    "        return DatasetGenerator(np.asarray(paths_input), np.asarray(paths_output), batch_size=batch_size)\n",
    "\n",
    "    def shuffled(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        idx = np.arange(len(self.paths_input))\n",
    "        np.random.shuffle(idx)\n",
    "        generator = DatasetGenerator(self.paths_input[idx], self.paths_output[idx],batch_size=self.batch_size)\n",
    "        generator.include_keys = self.include_keys\n",
    "\n",
    "\n",
    "        return generator\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.batch_size is None:\n",
    "            raise ValueError('Must set a batch size before iterating!')\n",
    "\n",
    "        self.index = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "        while(self.index * self.batch_size) < len(self.paths_input):\n",
    "            start = self.index * self.batch_size\n",
    "            stop = min(start + self.batch_size, len(self.paths_input))\n",
    "\n",
    "            X,Y = _parse_images(self.paths_input[start:stop],self.paths_output[start:stop])\n",
    "\n",
    "\n",
    "            self.index += 1\n",
    "            if self.include_keys:\n",
    "                return self.paths_input[start:stop], X,self.paths_output[start:stop], Y\n",
    "            else:\n",
    "                return X, Y\n",
    "\n",
    "\n",
    "        raise StopIteration\n",
    "    def __data_aug__(self,X,Y):\n",
    "\n",
    "        X,Y=data_augment(X,Y,self.batch_size)\n",
    "\n",
    "        return X,Y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_input)\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        if type(val) is not slice:\n",
    "            raise ValueError('DatasetGenerators can only be sliced')\n",
    "\n",
    "        sliced = DatasetGenerator(self.paths_input[val], self.paths_output[val],batch_size=self.batch_size)\n",
    "        sliced.include_keys = self.include_keys\n",
    "\n",
    "\n",
    "        return sliced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    root_folder = '../DATA_GHANA/DATASET/120_x_120_8_bands/TRAINING/'\n",
    "    test_save= '../DATA_GHANA/DATASET/120_x_120_8_bands/TEST_SAVE/'\n",
    "#     root_folder = '/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_pansh/TRAINING/'\n",
    "#     test_save= '/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_pansh/TEST_SAVE/'\n",
    "    if not os.path.exists(test_save):\n",
    "            os.makedirs(test_save)\n",
    "\n",
    "    batch_size = 5\n",
    "    \n",
    "    generator = DatasetGenerator.from_root_folder(root_folder, batch_size=batch_size)\n",
    "\n",
    "    generator=generator.shuffled()\n",
    "    generator =generator.__iter__()\n",
    "    \n",
    "    \n",
    "    for iteration in range(10):\n",
    "        X,Y=generator.__next__()\n",
    "\n",
    "\n",
    "#         for i in range(len(X)):\n",
    "#             for j in range(INPUT_SIZE):\n",
    "                \n",
    "#                 plt.imsave(test_save+'X_iter'+str(iteration)+'batch_'+str(i)+'_band_'+str(j)+'.jpg',X[i,:,:,j])\n",
    "#             for j in range(OUTPUT_SIZE):\n",
    "#                 plt.imsave(test_save+'Y_iter'+str(iteration)+'batch_'+str(i)+'_band_'+str(j)+'.jpg',Y[i,:,:,j])\n",
    "#         exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dhi",
   "language": "python",
   "name": "env_dhi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
