{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import *\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from numpy import newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH=120\n",
    "STRIDE=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(data,width,stride):\n",
    "    '''\n",
    "    Extract patches from images \n",
    "    :data input image \n",
    "    :width dimensiton of the patch\n",
    "    :stride stride of patch selection on the image\n",
    "    '''\n",
    "    print('Patch extraction with stride=%d and width=%d begins'%(stride,width) )\n",
    "    data_pl=tf.placeholder(tf.float64, [data.shape[0],data.shape[1],data.shape[2],data.shape[3]], name='data_placeholder')\n",
    "    data_o=tf.extract_image_patches(images=data_pl,ksizes=[1,width,width,1],strides=[1,stride,stride,1],rates=[1,1,1,1],padding='VALID')\n",
    "    print('Patch extraction done')\n",
    "    size_tot=data_o.get_shape().as_list()\n",
    "    data_o=tf.reshape(data_o,[size_tot[1]*size_tot[2],width,width,data.shape[3]])\n",
    "    with tf.Session() as sess:\n",
    "        Data_o= sess.run(data_o,feed_dict={data_pl: data})\n",
    "        print('%d patches of size %d x %d created as list'%(Data_o.shape[0],Data_o.shape[1],Data_o.shape[2]))\n",
    "        return Data_o\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the splitting for ORIGINAL SIZE of patches\n",
      "\n",
      "Length List panchro 10593\n",
      "Length List pansharp 10593\n",
      "Length List groundtruth 10593\n",
      "Split (TRAINING - VALIDATION:0.800000) - TEST:0.800000  done\n",
      "Training size:6779, Validation size:1695, Test size: 2119\n",
      "BUILD TRAINING SET\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_4_Shanghai_img5441_8.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_4_Shanghai_img5441_8.h5 created\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img2774_8.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img2774_8.h5 created\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_2_Vegas_img5416_8.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_2_Vegas_img5416_8.h5 created\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "Patch extraction with stride=120 and width=120 begins\n",
      "Patch extraction done\n",
      "9 patches of size 120 x 120 created as list\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_0.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_1.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_2.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_3.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_4.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_5.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_6.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_7.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/INPUT/input_5_Khartoum_img453_8.h5 created\n",
      "File/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_panshTRAINING/OUTPUT/output_5_Khartoum_img453_8.h5 created\n"
     ]
    }
   ],
   "source": [
    "path_raw='/scratch/SPACENET_DATA_PROCESSED/RAW_IMAGES/'\n",
    "\n",
    "path_dataset='/scratch/SPACENET_DATA_PROCESSED/DATASET/120_x_120_8_bands_pansh'\n",
    "if not os.path.exists(path_dataset):\n",
    "        os.makedirs(path_dataset)\n",
    "\n",
    "training_ratio=0.8 #so    test_ratio=0.2\n",
    "validation_ratio=0.2\n",
    "\n",
    "path_panchro=[]\n",
    "path_pansharp=[]\n",
    "path_groundtruth=[]\n",
    "\n",
    "for citydir in  sorted(os.listdir(path_raw)):\n",
    "    if citydir.startswith('AOI_1_RIO'):\n",
    "        continue\n",
    "    else:\n",
    "        for bandsdir in  sorted(os.listdir(os.path.join(path_raw,citydir))):\n",
    "            if bandsdir.startswith('PANCHRO'):\n",
    "                for filename in sorted(os.listdir(os.path.join(path_raw,citydir,bandsdir))):\n",
    "                    path_panchro.append(os.path.join(path_raw,citydir,bandsdir,filename))\n",
    "            if bandsdir.startswith('PANSHARP'):\n",
    "                for filename in sorted(os.listdir(os.path.join(path_raw,citydir,bandsdir))):\n",
    "                    path_pansharp.append(os.path.join(path_raw,citydir,bandsdir,filename))\n",
    "            if bandsdir.startswith('GROUNDTRUTH'):\n",
    "                for filename in sorted(os.listdir(os.path.join(path_raw,citydir,bandsdir))):\n",
    "                    path_groundtruth.append(os.path.join(path_raw,citydir,bandsdir,filename))\n",
    "    \n",
    "    \n",
    "print('Do the splitting for ORIGINAL SIZE of patches\\n')    \n",
    "path_panchro=np.asarray(path_panchro)\n",
    "print('Length List panchro %d'%path_panchro.shape)\n",
    "path_pansharp=np.asarray(path_pansharp)\n",
    "print('Length List pansharp %d'%path_panchro.shape)\n",
    "path_groundtruth=np.asarray(path_groundtruth)\n",
    "print('Length List groundtruth %d'%path_panchro.shape)\n",
    "\n",
    "\n",
    "idx_shuffle = np.arange(len(path_panchro))\n",
    "np.random.shuffle(idx_shuffle)\n",
    "\n",
    "\n",
    "path_panchro=path_panchro[idx_shuffle]\n",
    "path_pansharp=path_pansharp[idx_shuffle]\n",
    "path_groundtruth=path_groundtruth[idx_shuffle]\n",
    "\n",
    "\n",
    "#Do the split\n",
    "training_size=int(round(training_ratio*path_panchro.shape[0]))\n",
    "test_size=path_panchro.shape[0]-training_size\n",
    "validation_size=int(round(validation_ratio*training_size))\n",
    "training_size=training_size-validation_size\n",
    "\n",
    "print('Split (TRAINING - VALIDATION:%f) - TEST:%f  done'%(1-validation_ratio,training_ratio))\n",
    "print('Training size:%d, Validation size:%d, Test size: %d'%(training_size,validation_size,test_size))\n",
    "\n",
    "\n",
    "if not os.path.exists(path_dataset+'TRAINING'):\n",
    "        os.makedirs(path_dataset+'TRAINING')\n",
    "        if not os.path.exists(path_dataset+'TRAINING/INPUT'):\n",
    "            os.makedirs(path_dataset+'TRAINING/INPUT')\n",
    "        if not os.path.exists(path_dataset+'TRAINING/OUTPUT'):\n",
    "            os.makedirs(path_dataset+'TRAINING/OUTPUT')\n",
    "if not os.path.exists(path_dataset+'VALIDATION'):\n",
    "        os.makedirs(path_dataset+'VALIDATION')\n",
    "        if not os.path.exists(path_dataset+'VALIDATION/INPUT'):\n",
    "            os.makedirs(path_dataset+'VALIDATION/INPUT')\n",
    "        if not os.path.exists(path_dataset+'VALIDATION/OUTPUT'):\n",
    "            os.makedirs(path_dataset+'VALIDATION/OUTPUT')\n",
    "if not os.path.exists(path_dataset+'TEST'):\n",
    "        os.makedirs(path_dataset+'TEST')\n",
    "        if not os.path.exists(path_dataset+'TEST/INPUT'):\n",
    "            os.makedirs(path_dataset+'TEST/INPUT')\n",
    "        if not os.path.exists(path_dataset+'TEST/OUTPUT'):\n",
    "            os.makedirs(path_dataset+'TEST/OUTPUT')\n",
    "count_tr=0        \n",
    "print('BUILD TRAINING SET')\n",
    "for i in range(training_size):\n",
    "    filename=path_pansharp[i].split('pansharp_')[1]\n",
    "    filename=filename.split('.h5')[0]\n",
    "    \n",
    "    panchro=read_data_h5(path_panchro[i])\n",
    "    pansharp=read_data_h5(path_pansharp[i])\n",
    "    groundtruth=read_data_h5(path_groundtruth[i])\n",
    "    input_=np.concatenate((panchro,pansharp),axis=3)\n",
    "    output_=groundtruth\n",
    "    \n",
    "    input_=extract_patches(input_,WIDTH,STRIDE)\n",
    "    output_=extract_patches(output_,WIDTH,STRIDE)\n",
    "    \n",
    "    for j in range(input_.shape[0]):\n",
    "        write_data_h5(path_dataset+'TRAINING/INPUT/input_'+filename+'_'+str(j)+'.h5',input_[j,:,:,:])\n",
    "        write_data_h5(path_dataset+'TRAINING/OUTPUT/output_'+filename+'_'+str(j)+'.h5',output_[j,:,:,0])\n",
    "        count_tr+=1\n",
    "    \n",
    "\n",
    "print('BUILD VALIDATION SET')\n",
    "count_val=0\n",
    "for i in range(training_size,training_size+validation_size):\n",
    "    filename=path_pansharp[i].split('pansharp_')[1]\n",
    "    filename=filename.split('.h5')[0]\n",
    "    \n",
    "    panchro=read_data_h5(path_panchro[i])\n",
    "    pansharp=read_data_h5(path_pansharp[i])\n",
    "    groundtruth=read_data_h5(path_groundtruth[i])\n",
    "    input_=np.concatenate((panchro,pansharp),axis=3)\n",
    "    output_=groundtruth\n",
    "    \n",
    "    input_=extract_patches(input_,WIDTH,STRIDE)\n",
    "    output_=extract_patches(output_,WIDTH,STRIDE)\n",
    "    \n",
    "    for j in range(input_.shape[0]):\n",
    "        write_data_h5(path_dataset+'TRAINING/INPUT/input_'+filename+'_'+str(j)+'.h5',input_[j,:,:,:])\n",
    "        write_data_h5(path_dataset+'TRAINING/OUTPUT/output_'+filename+'_'+str(j)+'.h5',output_[j,:,:,0])\n",
    "        count_val+=1\n",
    "\n",
    "count_test=0\n",
    "\n",
    "print('BUILD TEST SET')\n",
    "for i in range(training_size+validation_size,list_input.shape[0]):\n",
    "    filename=path_pansharp[i].split('pansharp_')[1]\n",
    "    filename=filename.split('.h5')[0]\n",
    "    \n",
    "    panchro=read_data_h5(path_panchro[i])\n",
    "    pansharp=read_data_h5(path_pansharp[i])\n",
    "    groundtruth=read_data_h5(path_groundtruth[i])\n",
    "    input_=np.concatenate((panchro,pansharp),axis=3)\n",
    "    output_=groundtruth\n",
    "    \n",
    "    input_=extract_patches(input_,WIDTH,STRIDE)\n",
    "    output_=extract_patches(output_,WIDTH,STRIDE)\n",
    "    for j in range(input_.shape[0]):\n",
    "        write_data_h5(path_dataset+'TRAINING/INPUT/input_'+filename+'_'+str(j)+'.h5',input_[j,:,:,:])\n",
    "        write_data_h5(path_dataset+'TRAINING/OUTPUT/output_'+filename+'_'+str(j)+'.h5',output_[j,:,:,0])\n",
    "        count_test+=1\n",
    "    \n",
    "print('Elements in Training set %d'%count_tr) \n",
    "print('Elements in Validation set %d'%count_val)   \n",
    "print('Elements in Test set %d'%count_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dhi",
   "language": "python",
   "name": "env_dhi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
